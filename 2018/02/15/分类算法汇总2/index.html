<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="MachineLearning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="bagging,随机森林,Adaboost">
<meta name="keywords" content="MachineLearning">
<meta property="og:type" content="article">
<meta property="og:title" content="分类算法汇总(二)">
<meta property="og:url" content="http://yoursite.com/2018/02/15/分类算法汇总2/index.html">
<meta property="og:site_name" content="Chaowei's Blog">
<meta property="og:description" content="bagging,随机森林,Adaboost">
<meta property="og:image" content="http://yoursite.com/img/ML/37.png">
<meta property="og:image" content="http://yoursite.com/img/ML/38.png">
<meta property="og:image" content="http://yoursite.com/img/ML/39.png">
<meta property="og:updated_time" content="2018-07-21T07:41:29.938Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="分类算法汇总(二)">
<meta name="twitter:description" content="bagging,随机森林,Adaboost">
<meta name="twitter:image" content="http://yoursite.com/img/ML/37.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/02/15/分类算法汇总2/"/>





  <title> 分类算法汇总(二) | Chaowei's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?baa711a3bcbcb607e32347da955160de";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Chaowei's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/02/15/分类算法汇总2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Chaowei">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Chaowei's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                分类算法汇总(二)
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-15T17:31:25+08:00">
                2018-02-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/MachineLearning/" itemprop="url" rel="index">
                    <span itemprop="name">MachineLearning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/02/15/分类算法汇总2/" class="leancloud_visitors" data-flag-title="分类算法汇总(二)">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote class="blockquote-center"><p>bagging,随机森林,Adaboost </p>
</blockquote> 
<a id="more"></a>
<p>集成学习通过将多个学习器进行整合,常可获得比单一学习器显著优越的泛化性能,这对弱分类器尤为明显。</p>
<h2 id="bagging"><a href="#bagging" class="headerlink" title="bagging"></a>bagging</h2><p>自举汇聚法(booststrap aggregating)，也称为bagging方法，是在从原始数据集选择S次后得到S个新数据集的一种技术。<br>新数据集与原数据集大小相等，每个数据集都是通过在原始数据集中<font color="#FF000000">随机选择一个样本来进行替换得到的(这里也可以通过放回取样，新数据集中的每个样本都是从原数据集中有放回地随机抽样得到)</font><br>在S个数据集建好之后，将某个学习算法分别作用于每个数据集，就得到了S个分类器。<br>然后应用这S个分类器对新的数据进行分类，<font color="#FF000000">选择分类器投票结果最多的类别作为最后的分类结果</font>。<br>对于回归任务，采用的是简单平均的方法计算最后的结果。</p>
<h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>随机森林(Random Forest,RF)是bagging方法的一种扩展变体，以<font color="#FF000000">决策树</font>为基学习器，训练过程<font color="#FF000000">引入随机属性选择</font></p>
<h3 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h3><p>对于基决策树的每个结点，先从该结点的(d个)属性集合中随机选择一个包含k个属性的子集，再从这个子集选择一个最优属性用于划分，一般情况下推荐k=logd</p>
<p>1.如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本，作为该树的训练集；<br>2.随机地从d个特征中选取k个特征子集，每次树进行分裂时，从这k个特征中选择最优的；<br>3.每棵树都尽最大程度的生长，并且没有剪枝过程。</p>
<p><img src="/img/ML/37.png" alt="&quot;da&quot;"><br><img src="/img/ML/38.png" alt="&quot;da&quot;"></p>
<h3 id="算法特点"><a href="#算法特点" class="headerlink" title="算法特点"></a>算法特点</h3><p>1.基学习器多样性通过样本扰动和属性扰动实现<br>2.性能强大,被誉为“代表集成学习技术水平的方法”<br>3.算法简单、容易实现、计算开销小</p>
<h2 id="Adaboost"><a href="#Adaboost" class="headerlink" title="Adaboost"></a>Adaboost</h2><p>Adaboost是Adaptive boosting的缩写，它的自适应在于：<font color="#FF000000">前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器</font>。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器。</p>
<h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>Adaboost一般使用<font color="#FF000000">单层决策树</font>作为其弱分类器。单层决策树是决策树的最简化版本，只有一个决策点</p>
<p><img src="/img/ML/39.png" alt="&quot;da&quot;"></p>
<h3 id="实例代码"><a href="#实例代码" class="headerlink" title="实例代码"></a>实例代码</h3><p>先建立一个简单的数据集，并将其转为我们想要的数据格式，代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">#获取数据集</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadSimpData</span><span class="params">()</span>:</span></div><div class="line">    dataMat=matrix([[<span class="number">1.0</span>,<span class="number">2.1</span>],</div><div class="line">        [<span class="number">2.0</span>,<span class="number">1.1</span>],</div><div class="line">        [<span class="number">1.3</span>,<span class="number">1.0</span>],</div><div class="line">        [<span class="number">1.0</span>,<span class="number">1.0</span>],</div><div class="line">        [<span class="number">2.0</span>,<span class="number">1.0</span>]])</div><div class="line">    classLabels=[<span class="number">1.0</span>,<span class="number">1.0</span>,<span class="number">-1.0</span>,<span class="number">-1.0</span>,<span class="number">1.0</span>]</div><div class="line"><span class="keyword">return</span> dataMat,classLabels</div></pre></td></tr></table></figure>
<p>接下来，我们就要通过上述数据集来寻找最佳的单层决策树，最佳单层决策树是具有最低分类错误率的单层决策树，伪代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#构建单层分类器</span></div><div class="line"><span class="comment">#单层分类器是基于最小加权分类错误率的树桩</span></div><div class="line"><span class="comment">#伪代码</span></div><div class="line"><span class="comment">#将最小错误率minError设为+∞</span></div><div class="line"><span class="comment">#对数据集中的每个特征(第一层特征)：</span></div><div class="line">   <span class="comment">#对每个步长(第二层特征)：</span></div><div class="line">       <span class="comment">#对每个不等号(第三层特征)：</span></div><div class="line">           <span class="comment">#建立一颗单层决策树并利用加权数据集对它进行测试</span></div><div class="line">           <span class="comment">#如果错误率低于minError，则将当前单层决策树设为最佳单层决策树</span></div><div class="line"><span class="comment">#返回最佳单层决策树</span></div></pre></td></tr></table></figure>
<p>接下来看单层决策树的生成函数代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">#单层决策树的阈值过滤函数</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">stumpClassify</span><span class="params">(dataMatrix,dimen,threshVal,threshIneq)</span>:</span></div><div class="line">    <span class="comment">#对数据集每一列的各个特征进行阈值过滤</span></div><div class="line">    retArray=ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</div><div class="line">    <span class="comment">#阈值的模式，将小于某一阈值的特征归类为-1</span></div><div class="line">    <span class="keyword">if</span> threshIneq==<span class="string">'lt'</span>:</div><div class="line">        retArray[dataMatrix[:,dimen]&lt;=threshVal]=<span class="number">-1.0</span></div><div class="line">    <span class="comment">#将大于某一阈值的特征归类为-1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        retArray[dataMatrix[:,dimen]&gt;threshVal]=<span class="number">-1.0</span></div><div class="line"></div><div class="line">        </div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">buildStump</span><span class="params">(dataArr,classLabels,D)</span>:</span></div><div class="line"> <span class="comment">#将数据集和标签列表转为矩阵形式</span></div><div class="line">    dataMatrix=mat(dataArr);labelMat=mat(classLabels).T</div><div class="line">    m,n=shape(dataMatrix)</div><div class="line">    <span class="comment">#步长或区间总数 最优决策树信息 最优单层决策树预测结果</span></div><div class="line">    numSteps=<span class="number">10.0</span>;bestStump=&#123;&#125;;bestClasEst=mat(zeros((m,<span class="number">1</span>)))</div><div class="line">    <span class="comment">#最小错误率初始化为+∞</span></div><div class="line">    minError=inf</div><div class="line">    <span class="comment">#遍历每一列的特征值</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</div><div class="line">        <span class="comment">#找出列中特征值的最小值和最大值</span></div><div class="line">        rangeMin=dataMatrix[:,i].min();rangeMax=dataMatrix[:,i].max()</div><div class="line">        <span class="comment">#求取步长大小或者说区间间隔</span></div><div class="line">        stepSize=(rangeMax-rangeMin)/numSteps</div><div class="line">        <span class="comment">#遍历各个步长区间</span></div><div class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">-1</span>,int(numSteps)+<span class="number">1</span>):</div><div class="line">            <span class="comment">#两种阈值过滤模式</span></div><div class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">'lt'</span>,<span class="string">'gt'</span>]:</div><div class="line">            <span class="comment">#阈值计算公式：最小值+j(-1&lt;=j&lt;=numSteps+1)*步长</span></div><div class="line">            threshVal=(rangeMin+float(j)*stepSize)</div><div class="line">            <span class="comment">#选定阈值后，调用阈值过滤函数分类预测</span></div><div class="line">            predictedVals=\</div><div class="line">                stumpClassify(dataMatrix,i,threshVal,<span class="string">'inequal'</span>)</div><div class="line">            <span class="comment">#初始化错误向量</span></div><div class="line">            errArr=mat(ones((m,<span class="number">1</span>)))</div><div class="line">            <span class="comment">#将错误向量中分类正确项置0</span></div><div class="line">            errArr[predictedVals==labelMat]=<span class="number">0</span></div><div class="line">            <span class="comment">#计算"加权"的错误率</span></div><div class="line">            weigthedError=D.T*errArr</div><div class="line">            <span class="comment">#打印相关信息，可省略</span></div><div class="line">            <span class="comment">#print("split: dim %d, thresh %.2f,thresh inequal:\</span></div><div class="line">            <span class="comment">#    %s, the weighted error is %.3f",</span></div><div class="line">            <span class="comment">#    %(i,threshVal,inequal,weigthedError))</span></div><div class="line">            <span class="comment">#如果当前错误率小于当前最小错误率，将当前错误率作为最小错误率</span></div><div class="line">            <span class="comment">#存储相关信息</span></div><div class="line">            <span class="keyword">if</span> weigthedError&lt;minError:</div><div class="line">                minError=weigthedError</div><div class="line">                bestClasEst=predictedVals.copy()</div><div class="line">                bestStump[<span class="string">'dim'</span>]=i</div><div class="line">                bestStump[<span class="string">'thresh'</span>]=<span class="string">'threshVal'</span></div><div class="line">                bestStump[<span class="string">'ineq'</span>]=inequal</div><div class="line">    <span class="comment">#返回最佳单层决策树相关信息的字典，最小错误率，决策树预测输出结果</span></div><div class="line">    <span class="keyword">return</span> bestStump,minError,bestClasEst</div></pre></td></tr></table></figure>
<p>上面已经构建好了基于加权输入值进行决策的单层分类器，那么就已经有了实现一个完整AdaBoost算法所需要的所有信息了。下面先看一下整个AdaBoost的伪代码实现<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#完整AdaBoost算法实现</span></div><div class="line"><span class="comment">#算法实现伪代码</span></div><div class="line"><span class="comment">#对每次迭代：</span></div><div class="line">   <span class="comment">#利用buildStump()函数找到最佳的单层决策树</span></div><div class="line">   <span class="comment">#将最佳单层决策树加入到单层决策树数组</span></div><div class="line">   <span class="comment">#计算alpha</span></div><div class="line">   <span class="comment">#计算新的权重向量D</span></div><div class="line">   <span class="comment">#更新累计类别估计值</span></div><div class="line">   <span class="comment">#如果错误率为等于0.0，退出循环</span></div></pre></td></tr></table></figure></p>
<p>具体实现代码<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">#adaBoost算法</span></div><div class="line"> <span class="comment">#@dataArr：数据矩阵</span></div><div class="line"> <span class="comment">#@classLabels:标签向量</span></div><div class="line"> <span class="comment">#@numIt:迭代次数    </span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaBoostTrainDS</span><span class="params">(dataArr,classLabels,numIt=<span class="number">40</span>)</span>:</span></div><div class="line">    <span class="comment">#弱分类器相关信息列表</span></div><div class="line">    weakClassArr=[]</div><div class="line">    <span class="comment">#获取数据集行数</span></div><div class="line">    m=shape(dataArr)[<span class="number">0</span>]</div><div class="line">    <span class="comment">#初始化权重向量的每一项值相等</span></div><div class="line">    D=mat(ones((m,<span class="number">1</span>))/m)</div><div class="line">    <span class="comment">#累计估计值向量</span></div><div class="line">    aggClassEst=mat((m,<span class="number">1</span>))</div><div class="line">    <span class="comment">#循环迭代次数</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(numIt):</div><div class="line">        <span class="comment">#根据当前数据集，标签及权重建立最佳单层决策树</span></div><div class="line">        bestStump,error,classEst=buildStump(dataArr,classLabels,D)</div><div class="line">        <span class="comment">#打印权重向量</span></div><div class="line">        print(<span class="string">"D:"</span>,D.T)</div><div class="line">        <span class="comment">#求单层决策树的系数alpha</span></div><div class="line">        alpha=float(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/(max(error,<span class="number">1e-16</span>))))</div><div class="line">        <span class="comment">#存储决策树的系数alpha到字典</span></div><div class="line">        bestStump[<span class="string">'alpha'</span>]=alpha</div><div class="line">        <span class="comment">#将该决策树存入列表</span></div><div class="line">        weakClassArr.append(bestStump)</div><div class="line">        <span class="comment">#打印决策树的预测结果</span></div><div class="line">        print(<span class="string">"classEst:"</span>,classEst.T)</div><div class="line">        <span class="comment">#预测正确为exp(-alpha),预测错误为exp(alpha)</span></div><div class="line">        <span class="comment">#即增大分类错误样本的权重，减少分类正确的数据点权重</span></div><div class="line">        expon=multiply(<span class="number">-1</span>*alpha*mat(classLabels).T,classEst)</div><div class="line">        <span class="comment">#更新权值向量</span></div><div class="line">        D=multiply(D,exp(expon))</div><div class="line">        D=D/D.sum()</div><div class="line">        <span class="comment">#累加当前单层决策树的加权预测值</span></div><div class="line">        aggClassEst+=alpha*classEst</div><div class="line">        print(<span class="string">"aggClassEst"</span>,aggClassEst.T)</div><div class="line">        <span class="comment">#求出分类错的样本个数</span></div><div class="line">        aggErrors=multiply(sign(aggClassEst)!=\</div><div class="line">                    mat(classLabels).T,ones((m,<span class="number">1</span>)))</div><div class="line">        <span class="comment">#计算错误率</span></div><div class="line">        errorRate=aggErrors.sum()/m</div><div class="line">        print(<span class="string">"total error:"</span>,errorRate,<span class="string">"\n"</span>)</div><div class="line">        <span class="comment">#错误率为0.0退出循环</span></div><div class="line">        <span class="keyword">if</span> errorRate==<span class="number">0.0</span>:<span class="keyword">break</span></div><div class="line">    <span class="comment">#返回弱分类器的组合列表</span></div><div class="line">    <span class="keyword">return</span> weakClassArr</div></pre></td></tr></table></figure></p>
<p>测试算法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"> <span class="comment">#测试adaBoost，adaBoost分类函数</span></div><div class="line"> <span class="comment">#@datToClass:测试数据点</span></div><div class="line"> <span class="comment">#@classifierArr：构建好的最终分类器</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">adaClassify</span><span class="params">(datToClass,classifierArr)</span>:</span></div><div class="line">    <span class="comment">#构建数据向量或矩阵</span></div><div class="line">    dataMatrix=mat(datToClass)</div><div class="line">    <span class="comment">#获取矩阵行数</span></div><div class="line">    m=shape(dataMatrix)[<span class="number">0</span>]</div><div class="line">    <span class="comment">#初始化最终分类器</span></div><div class="line">    aggClassEst=mat(zeros((m,<span class="number">1</span>)))</div><div class="line">    <span class="comment">#遍历分类器列表中的每一个弱分类器</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(classifierArr)):</div><div class="line">        <span class="comment">#每一个弱分类器对测试数据进行预测分类</span></div><div class="line">        classEst=stumpClassify(dataMat,classifierArr[i][<span class="string">'dim'</span>],\</div><div class="line">                                classifierArr[i][<span class="string">'thresh'</span>],</div><div class="line">                                classifierArr[i][<span class="string">'ineq'</span>])</div><div class="line">        <span class="comment">#对各个分类器的预测结果进行加权累加</span></div><div class="line">        aggClassEst+=classifierArr[i][<span class="string">'alpha'</span>]*classEst</div><div class="line">        print(<span class="string">'aggClassEst'</span>,aggClassEst)</div><div class="line">    <span class="comment">#通过sign函数根据结果大于或小于0预测出+1或-1</span></div><div class="line">    <span class="keyword">return</span> sign(aggClassEst)</div></pre></td></tr></table></figure></p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>AdaBoost在每一轮的迭代过程中都会<font color="#FF000000">基于弱分类器的加权错误率，更新权重向量，从而进行下一次迭代。并且会在每一轮迭代中计算出该弱分类器的系数，该系数的大小将决定该弱分类器在最终预测分类中的重要程度</font>。这两点的结合是adaBoost算法的优势所在。</p>
<p>优点<br>1.Adaboost提供一种框架，在框架内可以使用各种方法构建子分类器。可以使用简单的弱分类器，<font color="#FF000000">不用对特征进行筛选，也不存在过拟合的现象。泛化错误率低，容易实现，可以应用在大部分分类器上，无参数调整</font><br>2.Adaboost算法<font color="#FF000000">不需要弱分类器的先验知识，最后得到的强分类器的分类精度依赖于所有弱分类器</font>。无论是应用于人造数据还是真实数据，Adaboost都能显著的提高学习精度。<br>3.Adaboost算法不需要预先知道弱分类器的错误率上限，且最后得到的强分类器的分类精度依赖于所有弱分类器的分类精度，可以深挖分类器的能力。Adaboost可以根据弱分类器的反馈，自适应地调整假定的错误率，执行的效率高。</p>
<p>缺点：<br>在Adaboost训练过程中，Adaboost会使得难于分类样本的权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。此外，Adaboost依赖于弱分类器，而弱分类器的训练时间往往很长。对离散数据点敏感</p>
<p>参考链接：<br>【1】《机器学习实战》Peter Harrington(美) 人民邮电出版社<br>【2】<a href="http://www.cnblogs.com/maybe2030/p/4585705.html" target="_blank" rel="external">[Machine Learning &amp; Algorithm] 随机森林（Random Forest）</a><br>【3】<a href="https://www.cnblogs.com/zy230530/p/6909288.html" target="_blank" rel="external">机器学习实战之AdaBoost算法</a><br>【4】<a href="https://www.cnblogs.com/ScorpioLu/p/8295990.html" target="_blank" rel="external">Adaboost原理详解</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/MachineLearning/" rel="tag"># MachineLearning</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/02/15/线性分类方法总结/" rel="next" title="线性分类方法总结">
                <i class="fa fa-chevron-left"></i> 线性分类方法总结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/02/02/分类算法汇总/" rel="prev" title="分类算法汇总(一)">
                分类算法汇总(一) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMDU1Ny83MTEy"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Chaowei" />
          <p class="site-author-name" itemprop="name">Chaowei</p>
           
              <p class="site-description motion-element" itemprop="description">Believe Amazing_Grace  --By小北</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">37</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/Chaowei0820" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/3515157181?refer_flag=1001030201_&is_hot=1" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  微博
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#bagging"><span class="nav-number">1.</span> <span class="nav-text">bagging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#随机森林"><span class="nav-number">2.</span> <span class="nav-text">随机森林</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本思想"><span class="nav-number">2.1.</span> <span class="nav-text">基本思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法特点"><span class="nav-number">2.2.</span> <span class="nav-text">算法特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adaboost"><span class="nav-number">3.</span> <span class="nav-text">Adaboost</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#算法流程"><span class="nav-number">3.1.</span> <span class="nav-text">算法流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实例代码"><span class="nav-number">3.2.</span> <span class="nav-text">实例代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点"><span class="nav-number">3.3.</span> <span class="nav-text">优缺点</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Chaowei</span>
</div>


<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<!--<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>-->


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  





  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>




  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  






  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("G4mO7GiazuroARxSJOi4JMR9-gzGzoHsz", "Q6jfXmr21nfFvuwOdhJBRa4c");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  

</body>
</html>
